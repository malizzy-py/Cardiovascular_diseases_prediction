# -*- coding: utf-8 -*-
"""Cardiovascular_Diseases.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NnS9KExn_9lKPZEQHz7QQsxBQLBpsLxP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay

# Pré-processamento

df = pd.read_csv('/cardio_train.csv', sep=';')
df['age'] = df['age'] / 365.25
df['age'] = df['age'].round().astype(int)
df.drop('id', axis=1, inplace=True)
df = df.dropna()
df.drop_duplicates(inplace=True)
display(df.head(40))

print(df.isnull().sum())

# Análise Exploratória

correlation_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Matriz de Correlação')
plt.show()

#Limpeza de outliers
df = df[(df['ap_hi'] > 70) & (df['ap_hi'] < 250)]
df = df[(df['ap_lo'] > 40) & (df['ap_lo'] < 140)]
df = df[df['ap_hi'] >= df['ap_lo']]

df['gender'] = df['gender'].astype('category')
df['cholesterol'] = df['cholesterol'].astype('category')
df['gluc'] = df['gluc'].astype('category')

# Definir a variável alvo (y) e as variaveis (X)
X = df.drop('cardio', axis=1)
y = df['cardio']

# Divisão em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Pipeline de Pré-processamento (Escalonamento e Codificação)

#Escalonamento
#Binárias (0/1): smoke, alco, active
# Multi-Classes: gender, cholesterol, gluc
numerical_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']
categorical_features_ohe = ['gender', 'cholesterol', 'gluc']

# Criar o pré-processador
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_ohe)
    ],
    remainder='passthrough'
)

# Grid Search
logreg_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('logreg', LogisticRegression(random_state=42, solver='liblinear'))
])

# Definir o espaço de busca de hiperparâmetros (Grid Search)
# Parâmetros focados em regularização (C) e tipo de regularização (penalty)
param_grid = {
    # C é o inverso da força de regularização (valores menores significam regularização mais forte)
    'logreg__C': [0.01, 0.1, 1, 10, 100],
    # 'l1' tende a zerar pesos (seleção de features), 'l2' apenas os diminui
    'logreg__penalty': ['l1', 'l2']
}

# Inicializar e executar o Grid Search
print("Iniciando Grid Search para otimização de hiperparâmetros...")
grid_search = GridSearchCV(
    logreg_pipe,
    param_grid,
    cv=5, # 5-fold Cross-Validation
    scoring='roc_auc', # Métrica de otimização
    n_jobs=-1 # Usar todos os núcleos disponíveis
)

grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
print("\nGrid Search Concluído!")
print(f"Melhores Hiperparâmetros: {grid_search.best_params_}")
print(f"Melhor Score AUC (Treinamento CV): {grid_search.best_score_:.4f}")

# Avaliação e Resultados Finais

y_pred = best_model.predict(X_test)
y_proba = best_model.predict_proba(X_test)[:, 1] # Probabilidade da classe 1

print("\n### Resultados Finais do Modelo Otimizado (Conjunto de Teste) ###\n")

accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_proba)
print(f"Acurácia (Accuracy): {accuracy:.4f}")
print(f"Área Sob a Curva ROC (AUC): {roc_auc:.4f}\n")

# Relatório de Classificação
print("Relatório de Classificação:\n", classification_report(y_test, y_pred))

#Visualização da Matriz de Confusão
conf_matrix = confusion_matrix(y_test, y_pred)
print("Matriz de Confusão:\n", conf_matrix)

plt.figure(figsize=(8, 6))
# ConfusionMatrixDisplay para visualização limpa
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Saudável (0)', 'Cardíaco (1)'])
disp.plot(cmap=plt.cm.Blues)
plt.title('Matriz de Confusão Otimizada')
plt.show()

# 4.3. Visualização da Curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Classificador Aleatório')
plt.xlabel('Taxa de Falso Positivo (False Positive Rate)')
plt.ylabel('Taxa de Verdadeiro Positivo (True Positive Rate)')
plt.title('Curva ROC - Regressão Logística Otimizada')
plt.legend(loc="lower right")
plt.show()

# NOVO LIMIAR
NEW_THRESHOLD = 0.40

y_pred_proba = best_model.predict_proba(X_test)[:, 1]

y_pred_new = (y_pred_proba >= NEW_THRESHOLD).astype(int)

# nova Matriz de Confusão
new_cm = confusion_matrix(y_test, y_pred_new)

new_fn = new_cm[1, 0]
new_fp = new_cm[0, 1]
new_recall = new_cm[1, 1] / (new_cm[1, 1] + new_cm[1, 0])

print("-" * 60)
print(f"RESULTADOS APÓS AJUSTE DO LIMIAR PARA {NEW_THRESHOLD:.2f}")
print(f"Novos Falsos Negativos (FN): {new_fn}")
print(f"Novos Falsos Positivos (FP): {new_fp}")
print(f"Novo Recall (Sensibilidade): {new_recall:.4f}")
print("-" * 60)


plt.figure(figsize=(8, 6))
sns.heatmap(new_cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            linewidths=.5, linecolor='black',
            yticklabels=['Real Negativo (0)', 'Real Positivo (1)'],
            xticklabels=['Previsto Negativo (0)', 'Previsto Positivo (1)'])

plt.title(f'Matriz de Confusão com Limiar Ajustado ({NEW_THRESHOLD:.2f})', fontsize=16)
plt.ylabel('Valor Real', fontsize=12)
plt.xlabel('Valor Previsto', fontsize=12)
plt.show()
