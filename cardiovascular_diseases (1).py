# -*- coding: utf-8 -*-
"""Cópia de Cardiovascular_Diseases.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lFNueA_WqFkrb_ctsnSfL9k8gzEqj0Mh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, ConfusionMatrixDisplay

# Pré-processamento

df = pd.read_csv('/cardio_train.csv', sep=';')
df['age'] = df['age'] / 365.25
df['age'] = df['age'].round().astype(int)
df.drop('id', axis=1, inplace=True)
df = df.dropna()
df.drop_duplicates(inplace=True)
display(df.head(40))

print(df.isnull().sum())

#Limpeza de outliers
df = df[(df['ap_hi'] > 70) & (df['ap_hi'] < 250)]
df = df[(df['ap_lo'] > 40) & (df['ap_lo'] < 140)]
df = df[df['ap_hi'] >= df['ap_lo']]

df['gender'] = df['gender'].astype('category')
df['cholesterol'] = df['cholesterol'].astype('category')
df['gluc'] = df['gluc'].astype('category')

# Definir a variável alvo (y) e as variaveis (X)
X = df.drop('cardio', axis=1)
y = df['cardio']

# Divisão em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Pipeline de Pré-processamento (Escalonamento e Codificação)

#Escalonamento
#Binárias (0/1): smoke, alco, active
# Multi-Classes: gender, cholesterol, gluc
numerical_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']
categorical_features_ohe = ['gender', 'cholesterol', 'gluc']

# Criar o pré-processador
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_ohe)
    ],
    remainder='passthrough'
)
print("Pipeline de Pré-processamento Criado.")

# DEFINIÇÃO DA VALIDAÇÃO CRUZADA (CV)
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
results_auc = {}
print(f"Validação Cruzada Estratificada (10-folds) configurada.")

# 3. EXECUÇÃO DA VALIDAÇÃO CRUZADA (Separada por Modelo para Melhor Acompanhamento)

# Modelo: Regressão Logística (Logistic Regression)
print("Avaliando Regressão Logística (LR) com 10-Fold CV")

model_lr = LogisticRegression(random_state=42, solver='liblinear')
pipe_lr = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model_lr)])

scores_lr = cross_val_score(pipe_lr, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
results_auc['Logistic Regression'] = scores_lr

print(f"  > Logistic Regression: AUC Média CV = {scores_lr.mean():.4f} (Desvio Padrão = {scores_lr.std():.4f})")

# ### 3.2. Modelo: Support Vector Machine (SVM) ###
print("Avaliando Support Vector Machine (SVM) com 10-Fold CV")

# probability=True é obrigatório para calcular o ROC AUC
model_svm = SVC(random_state=42, probability=True, gamma='auto')
pipe_svm = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model_svm)])

scores_svm = cross_val_score(pipe_svm, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
results_auc['SVM (SVC)'] = scores_svm

print(f"  > SVM (SVC): AUC Média CV = {scores_svm.mean():.4f} (Desvio Padrão = {scores_svm.std():.4f})")

# ### 3.3. Modelo: Random Forest (RF) ###
print("Avaliando Random Forest (RF) com 10-Fold CV")

model_rf = RandomForestClassifier(random_state=42, n_estimators=100)
pipe_rf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model_rf)])

scores_rf = cross_val_score(pipe_rf, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
results_auc['Random Forest'] = scores_rf

print(f"  > Random Forest: AUC Média CV = {scores_rf.mean():.4f} (Desvio Padrão = {scores_rf.std():.4f})")

# ### 3.4. Modelo: XGBoost (XGB) ###
print("Avaliando XGBoost com 10-Fold CV")

# eval_metric='logloss' é padrão para classificação binária
model_xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
pipe_xgb = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model_xgb)])

scores_xgb = cross_val_score(pipe_xgb, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)
results_auc['XGBoost'] = scores_xgb

print(f"  > XGBoost: AUC Média CV = {scores_xgb.mean():.4f} (Desvio Padrão = {scores_xgb.std():4f})")

#4. VISUALIZAÇÕES E AVALIAÇÃO DO MELHOR MODELO

#Plot de Comparação dos Resultados de CV

auc_df = pd.DataFrame(results_auc)

plt.figure(figsize=(12, 6))
sns.boxplot(data=auc_df)
plt.title('Comparação do AUC (10-Fold Cross-Validation) entre Modelos', fontsize=16)
plt.ylabel('AUC - Área Sob a Curva ROC', fontsize=12)
plt.xlabel('Modelo de Machine Learning', fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# --- 4.2. Avaliação do Modelo Vencedor no Conjunto de Teste ---

# Selecionar o melhor modelo baseado na média do AUC da Validação Cruzada
best_model_name = max(results_auc, key=lambda k: results_auc[k].mean())
# Obter o pipeline do modelo vencedor
best_model_params = model_lr if best_model_name == 'Logistic Regression' else \
                    model_svm if best_model_name == 'SVM (SVC)' else \
                    model_rf if best_model_name == 'Random Forest' else \
                    model_xgb

best_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_model_params)])

print(f"Modelo Vencedor (Melhor AUC Média CV): **{best_model_name}**")

# Treinar o modelo vencedor no conjunto de treinamento completo
best_pipeline.fit(X_train, y_train)

# Predição e Probabilidades no Conjunto de Teste
y_pred = best_pipeline.predict(X_test)
y_proba = best_pipeline.predict_proba(X_test)[:, 1] # Probabilidades da classe positiva (1)

# Métricas Finais
test_roc_auc = roc_auc_score(y_test, y_proba)
test_accuracy = best_pipeline.score(X_test, y_test)

print("\n### Resultados Finais do Modelo Vencedor (Conjunto de Teste) ###")
print(f"Modelo: **{best_model_name}**")
print(f"Acurácia (Accuracy): {test_accuracy:.4f}")
print(f"Área Sob a Curva ROC (AUC): {test_roc_auc:.4f}")
print("\nRelatório de Classificação:\n", classification_report(y_test, y_pred))

# --- 4.3. Visualização da Matriz de Confusão XGBoost---
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Saudável (0)', 'Cardíaco (1)'])
disp.plot(cmap=plt.cm.Blues)
plt.title(f'Matriz de Confusão - {best_model_name} (Conjunto de Teste)', fontsize=14)
plt.show()

# --- 4.4. Visualização da Curva ROC ---
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC - {best_model_name} (AUC = {test_roc_auc:.4f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Classificador Aleatório (AUC = 0.5)')
plt.xlabel('Taxa de Falso Positivo (False Positive Rate - 1 - Especificidade)')
plt.ylabel('Taxa de Verdadeiro Positivo (True Positive Rate - Sensibilidade/Recall)')
plt.title(f'Curva ROC - {best_model_name}')
plt.legend(loc="lower right")
plt.show()
